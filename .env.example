# === LLM Provider API Keys ===
# You only need to enter the keys for the providers you plan to use
GOOGLE_GENERATIVE_AI_API_KEY=****
OPENAI_API_KEY=****
XAI_API_KEY=****
ANTHROPIC_API_KEY=****
OPENROUTER_API_KEY=****
OLLAMA_BASE_URL=http://localhost:11434/api
GROQ_API_KEY=****
GROQ_BASE_URL=https://api.groq.com/openai/v1

# 智谱 AI (Zhipu AI)
# 获取 API Key: https://bigmodel.cn/usercenter/apikeys
ZHIPU_API_KEY=****
# 可选: 自定义 API 端点(用于代理或私有部署)
ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4


# (Optional) Default model to use when none is specified
# Format: provider/model (e.g., openRouter/qwen3-8b:free)
E2E_DEFAULT_MODEL=

# (Optional) Default agent to use when no agent is selected
# This agent will be automatically used when users don't manually select an agent
NEXT_PUBLIC_DEFAULT_AGENT_ID=
NEXT_PUBLIC_DEFAULT_AGENT_NAME=
NEXT_PUBLIC_DEFAULT_AGENT_ICON=


# === Database ===
# If you don't have PostgreSQL running locally, start it with: pnpm docker:pg
POSTGRES_URL=postgres://your_username:your_password@localhost:5432/your_database_name

# Secret for Better Auth (generate with: npx @better-auth/cli@latest secret)
BETTER_AUTH_SECRET=****

# (Optional)
# URL for Better Auth (the URL you access the app from)
# IMPORTANT: Set this to https://localhost:3000 if using HTTPS locally
# For production, this should match your domain (e.g., https://yourdomain.com)
BETTER_AUTH_URL=

# (Optional)
# === Tools ===
# Exa AI for web search and content extraction (optional, but recommended for @web and research features)
EXA_API_KEY=
# (Optional) Research Agent Task API base URL (used by task tools and activity panel)
# Example: https://research-agent.example.com
RESEARCH_AGENT_BASE_URL=
# (Optional) Research Agent Task workspace settings
RESEARCH_AGENT_WORKSPACE=workspace
RESEARCH_AGENT_USER_FILES_DIR=files
RESEARCH_AGENT_USER_LOGS_DIR=logs
RESEARCH_AGENT_LOG_DETAIL_PATH=logs/log_detail.jsonl
RESEARCH_AGENT_LOG_SUMMARY_PATH=logs/log_summary.json
RESEARCH_AGENT_LOG_RUN_PATH=logs/log_run.log


# (Optional)
# === Langfuse Observability ===
# Langfuse 是一个 LLM 应用的可观测性平台，用于追踪、监控和调试 AI 应用
# 文档: https://langfuse.com
# 获取密钥: https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
# 可选：Langfuse 服务器地址（默认：https://cloud.langfuse.com）
LANGFUSE_BASE_URL=https://us.cloud.langfuse.com



# ========================================================================
# === OPTIONAL SETTINGS BELOW (not required for basic functionality) ===
# ========================================================================


# (Optional)
# === RAGFlow Document Parsing ===
# RAGFlow for document parsing and chunk extraction
RAGFLOW_API_BASE=http://newsales.fanmikeji.cn
RAGFLOW_API_KEY=ragflow-kGcJg2uhNYWyxouiJ8ltUB4HldILZHaVgoCevLK8bFU
RAGFLOW_DATASET_ID=d8626358e00411f0ab7b2afe74304bc8
 
 

# RAGFlow 支持的 MIME 类型（逗号分隔）
# 音频：mp3, wav, m4a, ogg
# 文档：pdf, txt, md, doc, docx, xls, xlsx, ppt, pptx
# 数据：csv, json
RAGFLOW_SUPPORTED_MIME_TYPES=audio/mpeg,audio/wav,audio/mp4,audio/ogg,application/pdf,text/plain,text/markdown,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/vnd.ms-powerpoint,application/vnd.openxmlformats-officedocument.presentationml.presentation,text/csv,application/csv,application/json


# (Optional) Redis for Multi-Instance Support
# When running multiple server instances (load balancing, clustering):
# - With Redis: Real-time MCP synchronization + reduced polling
# - Without Redis: Polling-only synchronization (single instance or dev mode)
# redis://localhost:6379
REDIS_URL=


# (Optional)
# Whether to use file-based MCP config (default: false)
FILE_BASED_MCP_CONFIG=false

# (Optional) 
# === OAuth Settings ===
# Fill in these values only if you want to enable Google/GitHub/Microsoft login

#GitHub
GITHUB_CLIENT_ID=
GITHUB_CLIENT_SECRET=

#Google
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
# Set to 1 to force account selection
GOOGLE_FORCE_ACCOUNT_SELECTION=


# Microsoft
MICROSOFT_CLIENT_ID=
MICROSOFT_CLIENT_SECRET=
# Optional Tenant Id
MICROSOFT_TENANT_ID=
# Set to 1 to force account selection
MICROSOFT_FORCE_ACCOUNT_SELECTION=

# (Optional)
# Set this to 1 to disable email/password sign in completely
DISABLE_EMAIL_SIGN_IN=

# (Optional)
# Set this to 1 to disable email/password sign-ups (still allows sign-in for existing users)
DISABLE_EMAIL_SIGN_UP=

# (Optional)
# Set this to 1 to disable OAuth sign-ups (Google, GitHub, Microsoft)
DISABLE_SIGN_UP=

# (Optional)
# Set this to 1 to disallow adding MCP servers.
NOT_ALLOW_ADD_MCP_SERVERS=

# (Optional)
# Maximum timeout for MCP tool calls in milliseconds (default: no timeout)
# Useful for long-running MCP tools. Example: 600000 (10 minutes)
MCP_MAX_TOTAL_TIMEOUT=


# === File Storage ===

# -- Vercel Blob example --
# Pull the token locally with `vercel env pull` when testing against Vercel Blob.
# FILE_STORAGE_TYPE=vercel-blob
# FILE_STORAGE_PREFIX=uploads
# BLOB_READ_WRITE_TOKEN=


# -- S3 --
# FILE_STORAGE_TYPE=s3
# FILE_STORAGE_PREFIX=uploads
# FILE_STORAGE_S3_BUCKET=
# FILE_STORAGE_S3_REGION=
# Optional: Use when serving files via CDN/custom domain
# FILE_STORAGE_S3_PUBLIC_BASE_URL=https://cdn.example.com
# Optional: For S3-compatible endpoints (e.g., MinIO)
# FILE_STORAGE_S3_ENDPOINT=http://localhost:9000
# Optional: Force path-style URLs (1/true to enable)
# FILE_STORAGE_S3_FORCE_PATH_STYLE=1


# -- MINIO --
# FILE_STORAGE_TYPE=minio
# FILE_STORAGE_PREFIX=uploads

# Connection settings (default: http://localhost:9000)
MINIO_ENDPOINT=http://localhost:9000

# Credentials (default: minioadmin/minioadmin)
MINIO_USER=minioadmin
MINIO_PASSWORD=minioadmin

# Region (default: us-east-1)
MINIO_REGION=us-east-1

# SSL/TLS (default: false for local dev)
MINIO_USE_SSL=false

# Bucket name (default: uses FILE_STORAGE_PREFIX or "uploads")
MINIO_BUCKET=uploads

# Console port for Docker setup (default: 9001)
MINIO_CONSOLE_PORT=9001


# AWS Credentials (server only)
# The AWS SDK automatically discovers credentials in this order:
# 1) Environment variables below, 2) ~/.aws/credentials or AWS_PROFILE,
# 3) IAM role attached to the runtime (EC2/ECS/EKS/Lambda).
# You do NOT need to set these when using an IAM role.
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_SESSION_TOKEN=
# AWS_REGION=us-east-1
